{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrds\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the directory path\n",
    "directory = \"articles\"\n",
    "\n",
    "# initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# loop through each directory in the Articles directory\n",
    "for subdir in os.listdir(directory):\n",
    "    subdir_path = os.path.join(directory, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        # loop through each file in the directory\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            file_path = os.path.join(subdir_path, filename)\n",
    "            if os.path.isfile(file_path) and filename.endswith(\".json\"):\n",
    "                # read the JSON file\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    json_obj = json.load(f)\n",
    "                # extract the relevant information from the JSON object\n",
    "                _id = json_obj[\"_id\"]\n",
    "                #name of the directory is the company name\n",
    "                company = subdir\n",
    "                title = json_obj[\"title\"]\n",
    "                text = json_obj[\"text\"]\n",
    "                cleaned_text = re.sub(r'<p>|</p>', '', text)\n",
    "                #Change to timestamp YYYY-MM-DD HH:MM:SS\n",
    "                published = json_obj[\"published\"]\n",
    "                timestamp = datetime.strptime(published, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "                data.append([_id, company, title, cleaned_text, timestamp])\n",
    "        \n",
    "df = pd.DataFrame(data, columns=[\"id\", \"company\", \"title\", \"text\", \"published\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicates texts\n",
    "df = df.sort_values(['company', 'published'])\n",
    "df = df.drop_duplicates(subset=['company','text'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print company names\n",
    "company_to_ticker = {\n",
    "    '3M_Company': 'MMM',\n",
    "    'American_Express_co': 'AXP',\n",
    "    'Amgen_Inc': 'AMGN',\n",
    "    'Apple_Inc': 'AAPL',\n",
    "    'Boeing_Co': 'BA',\n",
    "    'Caterpillar_Inc': 'CAT',\n",
    "    'Chevron_Corporation': 'CVX',\n",
    "    'Cisco_Systems_Inc': 'CSCO',\n",
    "    'Coca_Cola_Co': 'KO',\n",
    "    'Dow_Inc': 'DOW',\n",
    "    'Goldman_Sachs_Group_Inc': 'GS',\n",
    "    'Home_Depot_Inc': 'HD',\n",
    "    'Honeywell_International_Inc': 'HON',\n",
    "    'Intel_Corporation': 'INTC',\n",
    "    'International_Business_Machines_Corporation': 'IBM',\n",
    "    'JPMorgan_Chase_Co': 'JPM',\n",
    "    'Johnson_Johnson': 'JNJ',\n",
    "    'McDonald_s_Corporation': 'MCD',\n",
    "    'Merck_Co_Inc': 'MRK',\n",
    "    'Microsoft_Corporation': 'MSFT',\n",
    "    'Nike_Inc': 'NKE',\n",
    "    'Procter_Gamble_Co': 'PG',\n",
    "    'Salesforce_Inc': 'CRM',\n",
    "    'The_Walt_Disney_Company': 'DIS',\n",
    "    'Travelers_Companies_Inc': 'TRV',\n",
    "    'Unitedhealth_Group_Incorporated': 'UNH',\n",
    "    'Verizon_communications_Inc': 'VZ',\n",
    "    'Visa_Inc': 'V',\n",
    "    'Walgreens_Boots_Alliance_Inc': 'WBA',\n",
    "    'Walmart_Inc': 'WMT'\n",
    "}\n",
    "\n",
    "#Replace company names with ticker symbols\n",
    "df['ticker'] = df['company'].map(company_to_ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helpers functions for cleaning text\n",
    "def remove_html_tags(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)\n",
    "\n",
    "def remove_ftcom_and_after(text):\n",
    "    index = text.find(\"FT.com\")\n",
    "    return text[:index] if index != -1 else text\n",
    "\n",
    "def remove_source_and_after(text) : \n",
    "    index  = text.find(\"Source:\")\n",
    "    return text[:index] if index != -1 else text\n",
    "\n",
    "def replace_PG(text):\n",
    "    return text.replace(\"P&amp;G\", \"Procter & Gamble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove html tags\n",
    "df['text'] = df['text'].apply(remove_html_tags)\n",
    "\n",
    "#Remove FT.com and after\n",
    "df['text'] = df['text'].apply(remove_ftcom_and_after)\n",
    "\n",
    "#Remove Source: and after\n",
    "df['text'] = df['text'].apply(remove_source_and_after)\n",
    "\n",
    "#Change P&G tokens \n",
    "df['text'] = df['text'].apply(replace_PG)\n",
    "\n",
    "#Remove &#xa0; and replace with space\n",
    "df['text'] = df['text'].str.replace('&#xa0;', ' ')\n",
    "\n",
    "#Remove \"Follow @FT\" and after\n",
    "df['text'] = df['text'].apply(lambda x: x.split(\"Follow @FT\")[0])\n",
    "\n",
    "#Remove rows with \"Please sign up here\n",
    "df = df[df['text'] != \"Please sign up here\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from difflib import SequenceMatcher\n",
    "\n",
    "# def similar_words(text, target, similarity_threshold=0.8):\n",
    "#     # Split the text into words\n",
    "#     words = text.split()\n",
    "\n",
    "#     # Find words that are similar to the target\n",
    "#     similar = [word for word in words if SequenceMatcher(None, word, target).ratio() > similarity_threshold]\n",
    "\n",
    "#     return similar\n",
    "\n",
    "# df['similar_words'] = df.apply(lambda row: similar_words(row['text'], row['company']), axis=1)\n",
    "\n",
    "#They are going to give us the list of words that are similar to the company name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_to_company = {'MMM' : '3m',\n",
    "                     'AXP' : 'american express',\n",
    "                     'AMGN' : 'amgen',\n",
    "                     'AAPL' : 'apple',\n",
    "                     'BA' : 'boeing',\n",
    "                     'CAT' : 'caterpillar',\n",
    "                     'CVX' : 'chevron',\n",
    "                     'CSCO' : 'cisco',\n",
    "                     'KO' : 'coca cola',\n",
    "                     'DOW' : 'dow',\n",
    "                     'GS' : 'goldman sachs',\n",
    "                     'HD' : 'home depot',\n",
    "                     'HON' : 'honeywell',\n",
    "                     'INTC' : 'intel',\n",
    "                     'IBM' : 'ibm',\n",
    "                     'JPM' : 'jpmorgan',\n",
    "                     'JNJ' : 'johnson & johnson',\n",
    "                     'MCD' : 'mcdonalds',\n",
    "                     'MRK' : 'merck',\n",
    "                     'MSFT' : 'microsoft',\n",
    "                     'NKE' : 'nike',\n",
    "                     'PG' : 'procter & gamble',\n",
    "                     'CRM' : 'salesforce',\n",
    "                     'DIS' : 'walt disney',\n",
    "                     'TRV' : 'travelers',\n",
    "                     'UNH' : 'united health',\n",
    "                     'VZ' : 'verizon',\n",
    "                     'V' : 'visa',\n",
    "                     'WBA' : 'walgreens',\n",
    "                     'WMT' : 'walmart'}\n",
    "\n",
    "df['company_words'] = df['ticker'].map(ticker_to_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower()\n",
    "df['sentences'] = df.apply(lambda row: [sentence for sentence in row['text'].split('. ') if row['company_words'] in sentence], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For delete the sentences that contain Listen on:\n",
    "df['sentences'] = df.apply(lambda row: [sentence for sentence in row['sentences'] if 'listen on:' not in sentence], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the dataframe to a csv file\n",
    "df.to_csv('data/news_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
