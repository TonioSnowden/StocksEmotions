{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VcVsDaPi-if"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "# Suppress all warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WA7MsIAXilR-",
        "outputId": "5211b2f2-9b8d-482b-c6dc-8d49b80960b2"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GR4Mol9TiFge"
      },
      "outputs": [],
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6efEejli0QG"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('news_cleaned.csv', sep = \";\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zrlsq_uQknzn"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=['Unnamed: 0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cr9BwbZGLoLf"
      },
      "outputs": [],
      "source": [
        "def split_into_sentences(s):\n",
        "    # Remove the leading and trailing square brackets and single quotes\n",
        "    s = s[2:-2]\n",
        "\n",
        "    # Split the string into a list of sentences\n",
        "    sentences = s.split(\"', '\")\n",
        "\n",
        "    return sentences\n",
        "\n",
        "# Apply the function to the 'sentences' column\n",
        "df['sentences'] = df['sentences'].apply(split_into_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jy21By_qrOch"
      },
      "outputs": [],
      "source": [
        "AAPL_df = df[df['ticker'] == 'AAPL']\n",
        "samples_100_AAPL = AAPL_df.sample(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFj0rTgmsJVR"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90vezojFkTK0"
      },
      "outputs": [],
      "source": [
        "def classify_sentences(sentences):\n",
        "    # Initialize the lists of headlines and scores\n",
        "    predictions = []\n",
        "    positives = []\n",
        "    negatives = []\n",
        "    neutrals = []\n",
        "\n",
        "    # Process each sentence\n",
        "    for sentence in sentences:\n",
        "        # Tokenize the sentence\n",
        "        inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "        # Get the model's prediction\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        # Get the predicted scores\n",
        "        scores = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "        prediction = outputs.logits.argmax(dim=-1).item()\n",
        "\n",
        "        # Add the sentence and scores to the lists\n",
        "        predictions.append(prediction)\n",
        "        positives.append(scores[:, 0].item())\n",
        "        negatives.append(scores[:, 1].item())\n",
        "        neutrals.append(scores[:, 2].item())\n",
        "\n",
        "    return predictions, positives, negatives, neutrals\n",
        "\n",
        "# Apply the function to the 'sentences' column and concatenate the results\n",
        "samples_100_AAPL[['Predictions', 'Positive', 'Negative', 'Neutral']] = samples_100_AAPL['sentences'].apply(lambda x: pd.Series(classify_sentences(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aUcBfQdR0Jz6",
        "outputId": "848b02f7-037e-4349-d9cb-8c71a9188673"
      },
      "outputs": [],
      "source": [
        "samples_100_AAPL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-fISCyj0GdT"
      },
      "outputs": [],
      "source": [
        "samples_100_AAPL.to_csv('output.csv', index=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
