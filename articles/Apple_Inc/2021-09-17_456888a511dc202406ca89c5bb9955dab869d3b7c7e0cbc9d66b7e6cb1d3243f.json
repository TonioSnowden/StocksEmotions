{
  "_id": "456888a511dc202406ca89c5bb9955dab869d3b7c7e0cbc9d66b7e6cb1d3243f",
  "feed": "wall-street-journal",
  "title": "The Facebook Files:  Facebook's Staff Flags -2-",
  "text": "<p>   The Facebook spokesman said the company doesn't follow that guidance. \"We prohibit human exploitation in no uncertain terms,\" Mr. Stone said. \"We've been combating human trafficking on our platform since 2015 and our goal remains to prevent anyone who seeks to exploit others from having a home on our platform.\" </p><p>   He added: \"We have a dedicated team that engages with law enforcement agencies across the globe. In instances of imminent harm, we may also provide relevant information to law enforcement in accordance with applicable law and our terms of service.\" </p><p>   In Ethiopia, armed groups have used Facebook to incite violence. The company's internal communications show it doesn't have enough employees who speak some of the relevant languages to help monitor the situation. For some languages, Facebook also failed to build automated systems, called classifiers, that could weed out the worst abuses. Artificial-intelligence systems that form the backbone of Facebook's enforcement don't cover most of the languages used on the site. </p><p>   Facebook also doesn't publish the \"community standards\" it requires users to abide by in all of the languages it serves in Ethiopia, so some users may not know the rules they are supposed to follow. </p><p>   Facebook said this week the standards are available in some Ethiopian languages and that it has started translating them into others. </p><p>   In a December planning document, a Facebook team wrote that the risk of bad consequences in Ethiopia was dire, and that \"most of our great integrity work over the last 2 years doesn't work in much of the world.\" It said in some high-risk places like Ethiopia, \"Our classifiers don't work, and we're largely blind to problems on our site.\" </p><p>   Groups associated with the Ethiopian government and state media posted inciting comments on Facebook against the Tigrayan minority, calling them \"hyenas\" and \"a cancer.\" Posts accusing Tigrayans of crimes such as money laundering were going viral, and some people on the site said the Tigrayans should be wiped out. </p><p>   Violence escalated toward the end of last year, when the government launched an attack on the Tigray capital, Mekelle. </p><p>   Secretary of State Antony Blinken said in March that Tigrayans are victims of ethnic cleansing. Ethiopia's government continues to commit violence against Tigrayans, the Journal reported last month. </p><p>   Facebook said this week it has increased its review capacity in various Ethiopian languages and improved its automated systems to stop harmful content. It said it has a team dedicated to reducing risks in Ethiopia that includes people from the area. </p><p>   Arabic is spoken by millions of Facebook users across what the company calls a highly sensitive region. Most of Facebook's content reviewers who work in the language speak Moroccan Arabic, and often aren't able to catch abusive or violent content in other dialects or make errors in restricting inoffensive posts, according to a December document. Facebook's enforcement algorithms also weren't capable of handling different dialects. </p><p>   \"It is surely of the highest importance to put more resources to the task of improving Arabic systems,\" an employee wrote in the document. </p><p>   When violence broke out between Israel and Palestinians months later, the company erroneously suppressed Arabic-language regional news sources and activists, and began removing posts that included the name \"Al Aqsa,\" an important Jerusalem mosque that was a focus of the conflict. Al Aqsa is also used in the name of the Al Aqsa Martyrs' Brigade, which the U.S. has designated as a terrorist organization. </p><p>   \"I want to apologize for the frustration these mistakes have caused,\" one manager wrote in an internal posting. </p><p>   The issue was previously reported by BuzzFeed. </p><p>   Facebook publicly apologized and said this week it now has a team focused on preventing similar errors. </p><p>   India has more than 300 million Facebook users, the most of any country. Company researchers in 2019 set up a test account as a female Indian user and said they encountered a \"nightmare\" by merely following pages and groups recommended by Facebook's algorithms. </p><p>   \"The test user's News Feed has become a near constant barrage of polarizing nationalist content, misinformation, and violence and gore,\" they wrote. The video service Facebook Watch \"seems to recommend a bunch of softcore porn.\" </p><p>   After a suicide bombing killed dozens of Indian paramilitary officers, which India blamed on rival Pakistan, the account displayed drawings depicting beheadings and photos purporting to show a Muslim man's severed torso. \"I've seen more images of dead people in the past 3 weeks than I've seen in my entire life total,\" one researcher wrote. </p><p>   In a 2017 mission statement, Mr. Zuckerberg said \"giving people a voice is a principle our community has been committed to since we began,\" and that the company would \"work on building new tools that encourage thoughtful civic engagement.\" </p><p>   In 2018, Facebook Chief Operating Officer Sheryl Sandberg told a Senate committee the company supports democratic principles around the world. When asked about Facebook's operations in Vietnam, she said, \"We would only operate in a country when we can do so in keeping with our values.\" </p><p>   Facebook restricted the ability of users in Vietnam from seeing the posts of Bui Van Thuan, a prominent critic of Vietnam's authoritarian government, for nine months beginning last year. Mr. Thuan said Facebook acted after a group organized by the government sent the company thousands of complaints about his posts. </p><p>   Facebook documents show the company's staff agreed the government organized efforts against Mr. Thuan, and used his case and a picture of him and his Facebook profile as an example of what they called systematic harassment. </p><p>   Facebook tallied 153,000 such reporting incidents over three months via 36 private groups, likely \"commissioned and directed by government/military entities.\" They said the efforts worked, with a \"good success % in suppressing the target FB presence.\" </p><p>   Facebook last year said it agreed to curtail access to dissident political content deemed illegal in exchange for the Vietnamese government ending its practice of slowing Facebook's local servers to pressure the company. </p><p>   A former Facebook employee who worked in Asia said Facebook is aware the Vietnamese government is using the platform to silence dissidents, but that it tolerates the abuse because Vietnam is a fast-growing advertising market. </p><p>   \"Our goal is to keep our services running in Vietnam so we can provide a space for as many people as possible to express themselves, connect with friends and run their business,\" Mr. Stone, the Facebook spokesman, said. \"As we shared last year, we do restrict some content in Vietnam to ensure our services remain available for millions of people who rely on them every day.\" </p><p>   Restrictions on Mr. Thuan's account were lifted last year, but he said he continues to face chronic harassment on Facebook. </p><p>   Facebook said this week his profile was restricted in error and the mistake has been corrected. </p><p>   Facebook's team of human-exploitation investigators, which in addition to the former police officer included a Polish financial expert who previously investigated trafficking finances at HSBC bank and a Moroccan refugee expert who formerly worked at the United Nations High Commissioner for Refugees, gathered evidence of human trafficking. </p><p>   By looking across Facebook products, they found criminal networks recruiting people from poor countries, coordinating their travel and putting them into domestic servitude or into forced sex work in the United Arab Emirates and other Persian Gulf countries. Facebook products facilitated each step, and the investigators followed communications across platforms to identify perpetrators and victims. </p><p>   Facebook in 2018 didn't have a protocol for dealing with recruiting posts for domestic servitude. In March 2018, employees found Instagram profiles dedicated to trafficking domestic servants in Saudi Arabia. An internal memo says they were allowed to remain on the site because the company's policies \"did not acknowledge the violation.\" </p><p>   The investigation team identified multiple trafficking groups in operation, including one with at least 20 victims, and organizers who spent at least $152,000 on Facebook ads for massage parlors. </p><p>   The former police officer recommended that Facebook disable WhatsApp numbers associated with the rings, put in new policies about ads purchased anonymously and improve its artificial intelligence to better root out posts related to human trafficking, according to the documents. He added that Facebook should develop a network to prevent trafficking by sharing findings with other tech companies. </p><p>   In another memo, the Polish trafficking expert wrote that 18 months after it first identified the problem, Facebook hadn't implemented systems to find and remove the trafficking posts. </p><p>   The BBC and Apple flagged concerns in 2019. With the threat posing \"potentially severe consequences to the business,\" the trafficking expert wrote, Facebook began moving faster. A proactive sweep using the investigation team's prior research found more than 300,000 instances of potential violations and disabled more than 1,000 accounts. </p><p>   The team continued finding posts of human trafficking, and Facebook struggled to put effective policies in place. One document says Facebook delayed a project meant to improve understanding of human trafficking. </p><p>   Another memo notes: \"We know we don't want to accept/profit from human exploitation. How do we want to calculate these numbers and what do we want to do with this money?\" </p><p>   At the end of 2020, following three months in which Facebook investigated a dozen networks suspected of human trafficking, a system for detecting it was deactivated. The trafficking investigators said that hurt their efforts, according to the documents. </p><p></p>",
  "published": "2021-09-17T06:09:00.000Z",
  "tags": [
    {
      "id": "US0378331005",
      "name": "Apple Inc.",
      "offsets": [
        {
          "start": 8899,
          "end": 8904
        }
      ],
      "nexusId": "10022657"
    }
  ]
}