{
  "_id": "d3c1c16a50423eaecc87fd3136a512241563661e522b73179b24a7133b38b48d",
  "feed": "wall-street-journal",
  "title": "EXCHANGE --- Business News -- Personal Technology: Wanted: More Control of Our Social-Media News Feeds",
  "text": "<p>Now Facebook Inc. has responded. And it . . . agrees?</p><p>This week the company announced a new bar that will appear at the top of our newsfeeds. It will allow you to toggle between the algorithmic, Facebook-curated feed and the full feed arranged in reverse chronological order. In an essay announcing several changes while broadly defending Facebook's algorithms, Nick Clegg, the company's vice president of global affairs, said it was working to give users better control of their relationship with the Facebook algorithm.</p><p>\"Do I think the controls we have introduced in the past were fully user-friendly enough? No, obviously not,\" Mr. Clegg told me in a follow-up interview. \"We're on a journey. There are many more things that we can and should do in the future to enhance both a feeling of human agency, as well as technically more usable controls.\"</p><p>Of course, if I had a chocolate bar for every time I heard a promise like that from a Facebook executive after a major backlash I'd be Willy Wonka. But after my conversation with Mr. Clegg, and looking at the new tools themselves, I do get a sense that Facebook is ready to give us some more control and some transparency into why we see what we see. Yes, the key word is some.</p><p>Starting now in Facebook's Android app, and coming soon to the iPhone app and the web, you get a choice of three feeds:</p><p>-- The Home feed, a fully algorithmic stream of content that Facebook thinks you'll want to see the most.</p><p>-- The Recent feed, a listing of all the posts from the accounts you follow, in reverse chronological order.</p><p>-- The Favorites feed, which shows posts from up to 30 friends and pages you've marked as favorites.</p><p>While you could reach these feeds before, you had to dig through menus more confusing than an airplane cockpit. As such, the new bar is a substantial improvement.</p><p>But what Facebook isn't giving you here is the ability to stick to your feed of choice -- unless your choice is that algorithmic Home feed. If you make another selection and then close the app, you'll be back Home when you reopen it.</p><p>Mr. Clegg also said Facebook is thinking about some deeper controls, specifically around customizing the topics you might see in your feed.</p><p>\"We're looking at the possibility of users being able to say they want more or less of content from certain kinds of posts like friends, groups or pages or possibly going further -- even, you know, you could turn the dial on a certain piece of content,\" he said. That could mean, say, turning down politics while turning up the sports.</p><p>In addition to user controls, Facebook is promising to tell us more about how its algorithm works -- why we see the things we see and why certain things are recommended to us.</p><p>I pressed Mr. Clegg on the reason we need more control and more transparency: the preponderance of clickable but dangerous content found on Facebook, including extremism, conspiracy theories, misinformation and more.</p><p>What's wrong, he told me, is \"this depiction that it's just a very, very crude sort of system that just spoon feeds the most unpleasant, poisonous incendiary stuff so that we somehow get a sugar rush or kind of emotional, angry reactions.\"</p><p>While sensational and clickbaity content does provoke more comments and engagement, he says, Facebook removes content that violates its rules, demotes content that is low quality and looks to promote more meaningful content. A sustainable product, he said, can't \"spoon-feed people rubbish to just have them hooked on for an extra 10, 15 minutes per day.\"</p><p>Nor is toxic content representative of what the majority of people see on Facebook, he added. \"I think the most popular post on Facebook in the U.S. on Monday was that video of that mother bear trying to get her baby cubs to cross a road.\"</p><p>I don't doubt that to be true. (And, oh my is the video adorable.) But it doesn't mean there might not have been problematic posts making the rounds of millions of accounts that same day.</p><p>Regardless, he says Facebook will take steps to help us better understand the content we see over the next year, including providing more transparency about how the spread of problematic content is reduced.</p><p>Facebook users should be encouraged by all of that, as well as the other new controls. What's emerging here and across the industry is a move to put the power over the content we see and the data we share back into our hands.</p><p>Is it all the control we'd want? No, but we should use the controls we're given. So go ahead and switch your Facebook feed to Recent and remember the rest of the prayer: \"Grant me the courage to change the things I can -- and wisdom to know the difference.\"</p>",
  "published": "2021-04-03T00:00:00.000Z",
  "tags": [
    {
      "id": "US0378331005",
      "name": "Apple Inc.",
      "offsets": [],
      "nexusId": "10022657"
    }
  ]
}