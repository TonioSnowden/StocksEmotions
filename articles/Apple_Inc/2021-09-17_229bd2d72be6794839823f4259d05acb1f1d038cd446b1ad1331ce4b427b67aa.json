{
  "_id": "229bd2d72be6794839823f4259d05acb1f1d038cd446b1ad1331ce4b427b67aa",
  "feed": "wall-street-journal",
  "title": "The Facebook Files:  Facebook's Staff Flags Criminals,  But Company Often Fails to Act  ---  Documents show alarm about what is on the site outside U.S., where user numbers are huge  ----  By Justin Scheck, Newley Purnell and Jeff Horwitz",
  "text": "<p>\n  [Fourth in a series] </p><pre>\n </pre><p>\n  In January, a former cop turned Facebook Inc. investigator posted an all-staff memo on the company's internal message board. It began \"Happy 2021 to everyone!!\" and then proceeded to detail a new set of what he called \"learnings.\" The biggest one: A Mexican drug cartel was using Facebook to recruit, train and pay hit men. </p><p>\n  The behavior was shocking and in clear violation of Facebook's rules. But the company didn't stop the cartel from posting on Facebook or Instagram, the company's photo-sharing site. </p><p>\n  Scores of internal Facebook documents reviewed by The Wall Street Journal show employees raising alarms about how its platforms are used in some developing countries, where its user base is already huge and expanding. They also show the company's response, which in many instances is inadequate or nothing at all. </p><p>\n  Employees flagged that human traffickers in the Middle East used the site to lure women into abusive employment situations in which they were treated like slaves or forced to perform sex work. They warned that armed groups in Ethiopia used the site to incite violence against ethnic minorities. They sent alerts to their bosses on organ selling, pornography and government action against political dissent, according to the documents. </p><p>\n  Facebook removes some pages, though many more operate openly, according to the documents. </p><p>\n  In some countries where Facebook operates, it has few or no people who speak the dialects needed to identify dangerous or criminal uses of the platform, the documents show. </p><p>\n  When problems have surfaced publicly, Facebook has said it addressed them by taking down offending posts. But it hasn't fixed the systems that allowed offenders to repeat the bad behavior. Instead, priority is given to retaining users, helping business partners and at times placating authoritarian governments, whose support Facebook sometimes needs to operate within their borders, the documents show. </p><p>\n  Facebook treats harm in developing countries as \"simply the cost of doing business\" in those places, said Brian Boland, a former Facebook vice president who oversaw partnerships with internet providers in Africa and Asia before resigning at the end of last year. Facebook has focused its safety efforts on wealthier markets with powerful governments and media institutions, he said, even as it has turned to poorer countries for user growth. </p><p>\n  \"There is very rarely a significant, concerted effort to invest in fixing those areas,\" he said. </p><p>\n  The developing world already has hundreds of millions more Facebook users than the U.S. -- more than 90% of monthly users are now outside the U.S. and Canada. With growth largely stalled there and in Europe, nearly all of Facebook's new users are coming from developing countries, where Facebook is the main online communication channel and source of news. Facebook is rapidly expanding into such countries, planning for technology such as satellite internet and expanded Wi-Fi to bring users online including in poor areas of Indonesia one document described as \"slums.\" </p><p>\n  The documents reviewed by the Journal are reports from employees who are studying the use of Facebook around the world, including human exploitation and other abuses of the platform. They write about their embarrassment and frustration, citing decisions that allow users to post videos of murders, incitements to violence, government threats against pro-democracy campaigners and advertisements for human trafficking. </p><p>\n  The material is part of extensive company communications reviewed by the Journal that offer unparalleled detail about the company's shortcomings in areas including rules that favor elites, teen mental health and efforts to manage its algorithm. </p><p>\n  Some of the most serious issues flagged by the documents are overseas. Activists have complained for years that Facebook does too little to protect overseas users from trouble it knows occurs on its platform. The documents show that many within Facebook agree. </p><p>\n  \"In countries at risk for conflict and violence, we have a comprehensive strategy, including relying on global teams with native speakers covering over 50 languages, educational resources, and partnerships with local experts and third-party fact checkers to keep people safe,\" Facebook spokesman Andy Stone said this week. </p><p>\n  The employee who identified the Mexican drug cartel is a former police officer and cybercrime expert hired in 2018 as part of a new investigation team focused largely on \"at-risk countries,\" where the rule of law is fragile and violence is common. </p><p>\n  That year, hate speech in Myanmar proliferated across Facebook's platforms, and the company has acknowledged it didn't do enough to stop incitements to violence against the minority Rohingya population, which the U.S. said were victims of ethnic cleansing. Executives described the Myanmar violence as a wake-up call to the company's responsibilities in the developing world. Chief Executive Mark Zuckerberg wrote a letter of apology to activists after initially playing down Facebook's role in the violence and pledged to do more. </p><p>\n  An internal Facebook report from March said actors including some states were frequently on the platform promoting violence, exacerbating ethnic divides and delegitimizing social institutions. \"This is particularly prevalent -- and problematic -- in At Risk Countries,\" the report says. </p><p>\n  It continues with a header in bold: \"Current mitigation strategies are not enough.\" </p><p>\n  The ex-cop and his team untangled the Jalisco New Generation Cartel's online network by examining posts on Facebook and Instagram, as well as private messages on those platforms, according to the documents. (Messages on WhatsApp, another Facebook product, are encrypted by default.) </p><p>\n  The team identified key individuals, tracked payments they made to hit men and discovered how they were recruiting poor teenagers to attend hit-man training camps. </p><p>\n  Facebook messages showed recruiters warning young would-be hires \"about being seriously beaten or killed by the cartel if they try to leave the training camp,\" the former officer wrote. </p><p>\n  The cartel, which law-enforcement officials say is the biggest criminal drug threat to the U.S., didn't hide its activity. It had multiple Facebook pages with photos of gold-plated guns and bloody crime scenes, the documents show. </p><p>\n  The Facebook pages were posted under the name \"CJNG,\" widely known as the shorthand for Cartel Jalisco Nueva Generacion, even though the company had internally labeled the cartel one of the \"Dangerous Individuals and Organizations\" whose pages should have been automatically removed from the platform under Facebook policy. </p><p>\n  The former cop recommended the company improve its follow-through to ensure bans on designated groups are enforced and seek to better understand cartel activity. </p><p>\n  Facebook didn't fully remove the cartel from its sites. The documents say it took down content tied to the cartel and disrupted the network. </p><p>\n  The investigation team asked another Facebook unit tasked with coordinating different divisions to look at ways to make sure a ban on the cartel could be enforced. That wasn't done effectively either, according to the documents, because the team assigned the job didn't follow up. </p><p>\n  On Jan. 13, nine days after the report was circulated internally, the first post appeared on a new CJNG Instagram account: A video of a person with a gold pistol shooting a young man in the head while blood spurts from his neck. The next post is a photo of a beaten man tied to a chair; the one after that is a trash bag full of severed hands. </p><p>\n  The page, along with other Instagram and Facebook pages advertising the cartel, remained active for at least five months before being taken down. Since then, new pages have appeared under the CJNG name featuring guns and beheadings. </p><p>\n  The former officer declined to comment on his findings, and Facebook declined to make him available for an interview. </p><p>\n  Facebook said this week its employees know they can improve their anti-cartel efforts, and that the company is investing in artificial intelligence to bolster its enforcement against such groups. </p><p>\n  Facebook commits fewer resources to stopping harm overseas than in the U.S., the documents show. </p><p>\n  In 2020, Facebook employees and contractors spent more than 3.2 million hours searching out and labeling or, in some cases, taking down information the company concluded was false or misleading, the documents show. Only 13% of those hours were spent working on content from outside the U.S. The company spent almost three times as many hours outside the U.S. working on \"brand safety,\" such as making sure ads don't appear alongside content advertisers may find objectionable. </p><p>\n  The investigation team spent more than a year documenting a bustling human-trafficking trade in the Middle East taking place on its services. On Facebook and Instagram, unscrupulous employment agencies advertised workers they could supply under coercive terms, using their photos and describing their skills and personal details. </p><p>\n  The practice of signing people to restrictive domestic employment contracts and then selling the contracts is widely abused and has been defined as human trafficking by the U.S. State Department. </p><p>\n  The company took down some offending pages, but took only limited action to try to shut down the activity until Apple Inc. threatened to remove Facebook's products from the App Store unless it cracked down on the practice. The threat was in response to a BBC story on maids for sale. </p><p>\n  In an internal summary about the episode, a Facebook researcher wrote: \"Was this issue known to Facebook before BBC enquiry and Apple escalation?\" </p><p>\n  The next paragraph begins: \"Yes.\" </p><p>\n  One document from earlier this year suggested the company should use a light touch with Arabic-language warnings about human trafficking so as not to \"alienate buyers\" -- meaning Facebook users who buy the domestic laborers' contracts, often in situations akin to slavery. </p><p></p>",
  "published": "2021-09-17T06:09:00.000Z",
  "tags": [
    {
      "id": "US0378331005",
      "name": "Apple Inc.",
      "offsets": [
        {
          "start": 9329,
          "end": 9339
        },
        {
          "start": 9629,
          "end": 9634
        },
        {
          "start": 9329,
          "end": 9334
        },
        {
          "start": 9329,
          "end": 9338
        }
      ],
      "nexusId": "10022657"
    }
  ]
}