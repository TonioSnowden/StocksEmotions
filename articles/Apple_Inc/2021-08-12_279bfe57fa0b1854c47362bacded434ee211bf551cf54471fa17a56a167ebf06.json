{
  "_id": "279bfe57fa0b1854c47362bacded434ee211bf551cf54471fa17a56a167ebf06",
  "feed": "ftcomall",
  "title": "Letter: Apple's new child protection policies should be applauded",
  "text": "<p>In his article about Apple's plans to introduce new child protection policies, Richard Waters suggests the way Apple went about it had “cut short debate” about the potential impact of their planned measures (<a href=\"https://www.ft.com/content/17013489-e88c-4345-8845-8a03b8b50f60\">Opinion</a>, August 10). Specifically Waters refers to Apple's plan to inspect content on users' devices before it is uploaded and placed into a strongly encrypted environment such as iCloud. Apple is going to do this in order to ensure the company is not aiding and abetting the distribution of child sexual abuse material. </p> <p>Sadly the “debate” has been going for at least five years and for the greater part of that time it has been completely frozen. Things intensified when, in March 2019, Facebook announced it were going to do the exact opposite of what Apple is now proposing. That too was a unilateral decision, made all the worse because, unlike with Apple, it was against a well-documented background of Facebook already knowing that its currently unencrypted Messenger and Instagram Direct platforms were being massively exploited for criminal purposes. In 2020 there were 20,307,216 reports to the US authorities of child sexual abuse material which had been exchanged over either Messenger or Instagram, but Facebook has so far given no sign that it will row back.</p> <p>The argument is, I'm afraid, a binary one. Once material is strongly encrypted it becomes invisible to law enforcement, the courts and the company itself. So either you are willing to live with that or you are not. Facebook is. Apple isn't. However, I suspect Apple's decision will force Facebook and others to reconsider. There are scalable solutions available which can respect user privacy while at the same time bearing down against at least certain types of criminal behaviour, in this case terrible crimes which harm children. </p> <p>If people believe Apple or indeed malevolent governments could misuse the technology, that is an important but different point which speaks to how we regulate or supervise the internet. </p> <p>It is emphatically not an argument which allows companies to continue doing nothing to curb illegality where technology exists which allows them to do so. </p> <p>Apple should be applauded. It has not just moved the needle, it has given it an enormous and wholly beneficial shove.</p> <p><strong>John Carr<br></strong><em>London NW5, UK</em></p><p>Source:  2021 'Letter: Apple's new child protection policies should be applauded' FT.com 12 August. Used under licence from the Financial Times. © The Financial Times Limited 2021. All Rights Reserved. </p><p>Please do not cut and paste FT articles and redistribute by email or post to the web.</p>",
  "published": "2021-08-12T00:16:53.282Z",
  "tags": [
    {
      "id": "US0378331005",
      "name": "Apple Inc.",
      "offsets": [
        {
          "start": 8,
          "end": 13
        },
        {
          "start": 1831,
          "end": 1836
        },
        {
          "start": 1508,
          "end": 1513
        },
        {
          "start": 259,
          "end": 264
        },
        {
          "start": 762,
          "end": 767
        },
        {
          "start": 396,
          "end": 401
        },
        {
          "start": 1540,
          "end": 1545
        },
        {
          "start": 21,
          "end": 26
        },
        {
          "start": 111,
          "end": 116
        },
        {
          "start": 862,
          "end": 867
        },
        {
          "start": 2154,
          "end": 2159
        }
      ],
      "nexusId": "10022657"
    }
  ]
}