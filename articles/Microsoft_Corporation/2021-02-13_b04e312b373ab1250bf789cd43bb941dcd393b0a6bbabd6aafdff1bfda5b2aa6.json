{
  "_id": "b04e312b373ab1250bf789cd43bb941dcd393b0a6bbabd6aafdff1bfda5b2aa6",
  "feed": "wall-street-journal",
  "title": "EXCHANGE  ---  Keywords:  How Do You Solve a Problem Like Online Speech?  ---  Legislators are targeting Section 230, the law that treats tech companies as neutral platforms. But few can agree on how to fix it.  ----  By Christopher Mims",
  "text": "<p>   Change is likely coming for Section 230, the law that protects online platforms from being held liable for things users say on them. As one of his last acts as president, Donald Trump attempted to strike down the law. President Biden has also said it should be revoked. </p><p>   More than 20 proposals to update Section 230 have surfaced on the Hill, originating from both sides of the aisle. Sens. Brian Schatz (D., Hawaii) and John Thune (R., S.D.), plan to reintroduce one of them, the PACT Act, in coming weeks. A competing bill was recently proposed by a trio of Democratic senators on Feb. 5. Its intention, as its backers wrote, is to make social-media companies \"accountable for enabling cyberstalking, targeted harassment and discrimination.\" </p><p>   There is broad agreement among experts and politicians that Section 230 won't be eliminated, but that's where accord ends. While many believe an update of the law is necessary and imminent, many others think most attempts to alter it are dangerous. </p><p>   The heads of some Big Tech companies, notably Facebook's Mark Zuckerberg (in October) and Microsoft's Satya Nadella (on Wednesday) have said they welcome more clarity on what sort of speech should be allowed under Section 230. Meanwhile, Twitter Chief Executive Jack Dorsey on Tuesday proposed a more \"market-driven\" approach to addressing the desire to update Section 230. Even if legislation is passed, it's not clear exactly what sort of cases will be brought to test the updated law, or what precedents those decisions will establish. </p><p>   \"Section 230 touches on everything from election integrity to online social-media bias,\" says Klon Kitchen, who was until recently director of the Center for Technology Policy at the politically conservative Heritage Foundation. If we try to solve all the problems of the internet by making changes to this one law, he adds, we'll be overwhelmed by their unintended consequences. </p><p>   Passed in 1996, Section 230 of the Communications Decency Act was intended to protect and promote America's then-nascent internet industry. It goes, roughly, like this: As long as sites aren't knowingly helping their users commit crimes, what users share on these sites is the users' own responsibility. Section 230 makes the business models of giants including Facebook and Google possible. It's the reason upstarts from TikTok to Parler can exist. And it enables countless other businesses, such as Airbnb. </p><p>   Much has changed since 1996. Then, there were 36 million people on the internet, most of them in the U.S. Now there are 4.8 billion, including 90% of Americans. </p><p>   According to a survey by Pew published in July, 72% of U.S. adults say social-media companies have too much power and influence in politics. </p><p>   Many Democrats are worried that platforms have used the protections of Section 230 as an excuse to let some kinds of speech run rampant; many Republicans believe they've used it to police speech too much. Some want to add clarifying language to Section 230, while others want \"carve-outs,\" which make it explicit that companies receive liability protections only if they play by certain rules. A few, including Sens. Josh Hawley (R., Mo.) and Ted Cruz (R., Texas), want Section 230 gutted. </p><p>   The potential negative ramifications of wiping out Section 230 without having an adequate replacement, however, would be considerable, and could seriously damage the U.S. economy, says Mr. Kitchen. </p><p>   Reverting to their pre-1996 legal status would mean websites and apps that act to moderate content in any way would be responsible for everything they host. Services like Facebook and YouTube would either have to stop moderating and open the floodgates to hate speech and other harmful content, or moderate and be potentially crushed by lawsuits for harms arising from what their users post. Most likely, they'd have to drastically narrow the scope of what's permitted on their platforms. </p><p>   For users on Twitter or Instagram, this could mean hitting \"share\" and then hoping your post makes it past an army of automated filters and human reviewers that would put existing hurdles to shame. Meanwhile, someone would have to vet and vouch for every Google search result and Airbnb listing ahead of time. If this poses a crushing burden for America's trillion-dollar tech behemoths, it would be infinitely worse for startups. </p><p>   Given that, most proposals focus on upgrading and expanding Section 230, not blowing it out an airlock. </p><p>   Sens. Mark R. Warner (D., Va.), Mazie Hirono (D., Hawaii) and Amy Klobuchar (D., Minn.) proposed the SAFE TECH Act this month. A grab bag of a half-dozen proposals, it makes platforms liable for both ads they run and harassment they enable, and would allow (for example) Rohingya survivors to sue Facebook in U.S. court for what the United Nations has alleged is the company's role in the Myanmar genocide. </p><p>   In addition, the bill would change what Section 230 protects from \"information\" to \"speech.\" This change would put all sorts of conduct outside the law's protection, from gun sales to fraudulent transactions, and force platforms to do something about them. </p><p>   Some scholars warn that the SAFE TECH Act could be nearly as threatening to the internet economy as eliminating Section 230 entirely. </p><p>   One provision enables claims against sites that receive or make payments for content. Daphne Keller, director of the Program on Platform Regulation at Stanford University and former associate general counsel at Google, says this could bring more lawsuits against entities such as Amazon Web Services, which could be liable for content shared by its customers' users. </p><p>   \"This legislation has some admirable goals,\" said Sen. Ron Wyden (D., Ore.), one of the original authors and sponsors of Section 230. \"Unfortunately, as written, it would devastate every part of the open internet, and cause massive collateral damage to online speech.\" </p><p>   A Pew survey published in August says that 90% of Republicans believe social-media sites censor political viewpoints. Some researchers have found the opposite is true. A just-published report from researchers at New York University found that in general, social media privileges and amplifies the views of right-wing users. </p><p>   The PACT Act, originally proposed in June 2020, would require online platforms to explain their content-moderation practices clearly, require quarterly reports on what content has been removed, and impose less stringent requirements on small online platforms, to avoid placing undue burdens on startups without the same resources as Big Tech. </p><p>   Whatever happens to Section 230, any changes to it can't possibly solve all of the problems of the internet that it has enabled. </p><p>   \"We've basically moved aspects of every kind of good and bad human behavior online, with consequences that are sometimes awful and very often complicated,\" says Ms. Keller. \"Now pundits and some people in D.C. have become convinced that we can tackle all of that by amending this one little law.\" </p><p></p>",
  "published": "2021-02-13T07:09:00.000Z",
  "tags": [
    {
      "id": "US5949181045",
      "nexusId": "10031144",
      "name": "Microsoft Corporation",
      "offsets": [
        {
          "start": 1082,
          "end": 1091
        },
        {
          "start": 1082,
          "end": 1093
        }
      ]
    }
  ]
}