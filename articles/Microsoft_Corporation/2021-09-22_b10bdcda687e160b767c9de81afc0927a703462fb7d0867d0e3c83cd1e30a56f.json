{
  "_id": "b10bdcda687e160b767c9de81afc0927a703462fb7d0867d0e3c83cd1e30a56f",
  "feed": "wall-street-journal",
  "title": "Hiring and AI: Let Job Candidates Know Why They Were Rejected; As more companies use artificial intelligence in their hiring decisions, here's one way to make the system more transparent",
  "text": "<p>How would this work? When people apply for a job, they will see a list of the hiring criteria, such as degree requirements, specific skills and the number of years of experience, so that they know precisely what a company is looking for. Then, if the applicant is rejected, the AI will present them with another list, showing where they didn't meet the criteria or compared unfavorably to other applicants—the reasoning behind the decision.</p><p>In other words, we should show people very clearly what factors are used to judge them, just as we show people the ingredients that go into their food.</p><p>We desperately need such a system. AI's widespread use in hiring far outpaces our collective ability to keep it in check—to understand, verify and oversee it. Is a résumé screener identifying promising candidates, or is it picking up irrelevant, or even discriminatory, patterns from historical data? Is a job seeker participating in a fair competition if he or she is unable to pass an online personality test, despite having other qualifications needed for the job?</p><p>A two-tier system</p><p>The labels I propose would come in two parts. First, the \"posting label,\" a short, simple and clear set of requirements that an AI screener will be looking for in applicants. For example, the posting label for an art-director position might list \"B.S. in communications or similar,\" \"two years of full-time experience\" and \"expert knowledge of Adobe Design Suite.\"</p><p>The posting label also would explain the assessment process. Will the AI consider only submitted résumés, or also use applicants' public LinkedIn profiles and Twitter feeds? What about their credit histories? Will a video interview be required? Which parts of the application are processed by a machine and which by a human?</p><p>A posting label for an accountant position, for instance, may list résumé, LinkedIn, Twitter and credit scores as the sources of information, and it may state that personality scores will be used to assess the candidate, with preference given to candidates with higher S (\"steady\") and C (\"conscientious\") scores.</p><p>The label would also provide actionable information. It would state, for instance, that a job applicant is allowed to correct some data that the company uses to make decisions or contest the company's use of their personal information, such as their social-media feed.</p><p>In addition, applicants should be informed that they can request accommodations if they have reason to believe that a certain kind of assessment would discriminate against them. For example, scoring a video interview based in part on making eye contact with the camera would disadvantage people with limited vision or autism.</p><p>Critically, the posting label enables informed consent: Job seekers agree to the assessment procedure by submitting their applications, and they opt out by deciding not to apply if they object to the employer's data practices (e.g., using an applicant's credit score) or assessment methodology (e.g., constructing an estimation of an applicant's personality based on a résumé or performance in an online game).</p><p>If a job seeker applies for the job but isn't selected, then he or she would receive a \"decision label\" along with the rejection. This label would show how the applicant's qualifications measured up to the job requirements; how the applicant compared with other job seekers; and how information about these qualifications was extracted.</p><p>For example, a portion of the applicant's résumé may be highlighted to explain that he or she lacked sufficient experience for the position. Or a tweet may be highlighted to substantiate a low \"conscientious\" score on a personality test. This information would allow the applicant to accept or contest the hiring decision.</p><p>Explaining the choice</p><p>Having clear criteria for decisions not only helps applicants—it also gives employers vital information.</p><p>Many times, AI makes judgment calls that are opaque. Employers often don't know what data AI screeners are using, or how they analyze that data to make a final decision. The labels can show managers the factors that the AI is using to screen applicants—and let those managers decide if those factors need to be changed.</p><p>SHARE YOUR THOUGHTS</p><p>What do you think are the advantages and drawbacks of using AI in hiring? Join the conversation below.</p><p>For instance, does the AI need to be given more—or different—training data, covering different job roles and demographic groups, to avoid making biased and arbitrary decisions? Likewise, what is the predictive accuracy of the tool for different demographic groups? What features of past applicants' profiles led to a positive or a negative decision by the tool, and can job relevance of these features be substantiated?</p><p>One concern may be that these labels will motivate strategic manipulation or \"gaming.\" However, there is already strategic manipulation happening: Career services routinely offer training and advice on how to make a résumé attractive to algorithmic tools. Greater transparency will help alleviate unproductive gaming and tilt the balance in favor of positive change, motivating individuals to actually improve their qualifications, rather than to make it seem like they are qualified.</p><p>Humans—and not AI—should ultimately make the final call on whom to hire. But, like it or not, many managers use AI systems at different stages of the hiring process—and that practice is only going to become more common. If managers are relying on AI, those tools should be as transparent as possible, and job seekers should have a say in how their data is used.</p><p>Ultimately, hiring is complex. It is a multistep process in which we trade off objective criteria, such as an applicant's degree requirements and measurable skills, against subjective factors such as how well they will fit into the team and pick up new skills.</p><p>We bring in AI to help alleviate some of this complexity. But we cannot forget that AI tools work to specification, and they do best when those specifications are clear. We can use AI effectively for parts of the hiring process—to identify clear requirements-based matches. But AI tools cannot exercise discretion or apply subjective judgment. My hope is that nutritional labels will help us come to a consensus on which decisions we should leave to an AI, and which we should make ourselves.</p><p>Dr. Stoyanovich is institute associate professor of computer science and engineering at the Tandon School of Engineering, associate professor of data science at the Center for Data Science and director of New York University's Center for Responsible AI. She can be reached at reports@wsj.com.</p><p>Hiring and AI: Let Job Candidates Know Why They Were Rejected</p>",
  "published": "2021-09-22T15:00:00.000Z",
  "tags": [
    {
      "id": "US5949181045",
      "nexusId": "10031144",
      "name": "Microsoft Corporation",
      "offsets": []
    }
  ]
}