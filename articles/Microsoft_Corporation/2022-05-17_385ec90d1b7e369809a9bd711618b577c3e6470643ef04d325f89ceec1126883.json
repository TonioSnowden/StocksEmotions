{
  "_id": "385ec90d1b7e369809a9bd711618b577c3e6470643ef04d325f89ceec1126883",
  "feed": "wall-street-journal",
  "title": "Massacre Data Arrives a Day Late; The Buffalo shooter and his ilk give themselves away if we look hard enough.",
  "text": "<p>Gun control might be the answer for all kinds of gun crimes, from armed robberies and family homicide to gang shootouts in downtown Chicago and planned event-style massacres like those in Orange County and Buffalo, if the gun control were far-reaching enoughâ€”that is, if it seriously rolled back the right of individual Americans to buy and own guns.</p><p>Even Democrats, the pro-gun-control party, can't find backing in their own caucus for restrictions that would have a significant effect on such crimes. In contrast, Americans have shown willy-nilly, with their tolerance of everything from online tracking to E-ZPass, from traffic cameras and license-plate readers to in-store face-recognition, that they are willing to stomach a good deal of intrusive if passive surveillance.</p><p>A gun control revolution isn't about to happen. Even advocates of such a revolution pipe up these days mainly out of a seeming need to express despair and disdain for fellow Americans who place a higher value on their right to own guns. And yet a different mind-set, less marinated in learned helplessness, would ask what other strategies might be tried. Especially with respect to domestic terrorist-style mass shootings, the answer is obvious: surveillance powered by big data, whose advancing role in our world seems unstoppable in any case.</p><p>The information exists, as its near instant assembly into an intelligible pattern after the Buffalo killings and so many others testifies. In an irony, in the same New York Times on Tuesday that featured many laments for the lost gun-control cause, another article mourned the irresistible spread in the workplace of employee-monitoring software. As the paper explained, \"corporate employers fear that employees could leak information, allow access to confidential files, contact clients inappropriately or, in the extreme, bring a gun to the office.\"</p><p>Because the data exist, because monitoring is cheap, because failing to do so exposes a business and its public to risk, employers are naturally driven to attempt to head off trouble by seeking patterns that are there for the finding: \"Software can watch for suspicious computer behavior or it can dig into an employee's credit reports, arrest records and marital-status updates. It can check to see if Cheryl is downloading bulk cloud data or run a sentiment analysis on Tom's emails to see if he's getting testier over time.\"</p><p>Longtime readers will sigh. I've made similar points after half a dozen domestic terrorist-style events from Las Vegas and suburban Denver to a congressional ballfield in suburban D.C. Red flags, police calls and electronic hints and giveaways were always conspicuous in hindsight. A decade ago it was plausible to argue, as some did, that algorithms would be too slow to yield relevant patterns and would cough up too many false positives. However, throwing away a decade is hardly a way to make progress on these challenges.</p><p>The real stumbling block is privacy risk. Privacy risk, let us notice, resides in who can see the data, not whether it exists, and in when and how it might be permissible to tie a potentially significant pattern to a named individual.</p><p>In 2017 researchers from Columbia University and Microsoft showed that the queries of individual search-engine users could yield recognizable patterns connecting nonspecific symptom searches with later searches suggesting the user had received a pancreatic cancer diagnosis. Of course, because researchers couldn't identify the individuals involved, they couldn't ask whether any had actually received such a diagnosis nor could they put their insight to work helping real patients get earlier diagnosis of a disease that is often diagnosed too late to help.</p><p>That's the privacy hurdle. A plausible solution would be wrapping the whole puzzle in a specialized legal process: The algorithms would be allowed to do their job; a judge's permission would be required before a named person could be linked to an observed pattern so government officials could take steps. The opportunity exists whether we choose to take advantage of it or not, but history suggests that sooner or later we will take advantage of it.</p><p>Massacre Data Arrives a Day Late</p>",
  "published": "2022-05-17T22:02:00.000Z",
  "tags": [
    {
      "id": "US5949181045",
      "nexusId": "10031144",
      "name": "Microsoft Corporation",
      "offsets": [
        {
          "start": 3214,
          "end": 3223
        }
      ]
    }
  ]
}