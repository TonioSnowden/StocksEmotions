{
  "_id": "8f7b80839febca4a9e625f93b19321adc6569316a6623dbd53dc28103589f28f",
  "feed": "wall-street-journal",
  "title": "EXCHANGE --- Keywords: AI's Big Chill --- Some experts in artificial intelligence think the field's name fuels confusion and hype of the sort that led to past 'AI winters' of disappointment",
  "text": "<p>This might seem like a purely academic debate. Whatever we call it, surely what matters most about \"AI\" is the way it is already transforming what can seem like almost every industry on earth? Not to mention the potential it has to displace millions of workers in trades ranging from white to blue collar, from the back office to trucking?</p><p>And yet, across the fields it is disrupting or supposed to disrupt, AI has fallen short of many of the promises made by some of its most vocal advocates -- from the disappointment of IBM's Watson to the forever-moving target date for the arrival of fully self-driving vehicles.</p><p>Words have power. And -- ask any branding or marketing expert -- names, in particular, carry weight. Especially when they describe systems so complicated that, in their particulars at least, they are beyond the comprehension of most people.</p><p>Inflated expectations for AI have already led to setbacks for the field. In both the early 1970s and late 1980s, claims similar to the most hyperbolic ones made in the past decade -- about how human-level AI will soon arise, for example -- were made about systems that would seem primitive by today's standards. That didn't stop extremely smart computer scientists from making them, and the disappointing results that followed led to \"AI winters\" in which funding and support for the field dried up, says Melanie Mitchell, an AI researcher and professor at the Santa Fe Institute with more than a quarter-century of experience in the field.</p><p>No one is predicting another AI winter anytime soon. Globally, $37.9 billion has been invested in AI startups in 2021 so far, on pace to roughly double last year's amount, according to data from PitchBook. And there have also been a number of exits for investors in companies that use and develop AI, with $14.4 billion in deals for companies that either went public or were acquired.</p><p>But the muddle that the term AI creates fuels a tech-industry drive to claim that every system involving the least bit of machine learning qualifies as AI, and is therefore potentially revolutionary. Calling these piles of complicated math with narrow and limited utility \"intelligent\" also contributes to wild claims that our \"AI\" will soon reach human-level intelligence. These claims can spur big rounds of investment and mislead the public and policy makers who must decide how to prepare national economies for new innovations.</p><p>Inside and outside the field, people routinely describe AI using terms we typically apply to minds. That's probably one reason so many are confused about what the technology can actually do, says Dr. Mitchell.</p><p>Claims that AI will soon significantly exceed human abilities in multiple domains -- not just in very narrow tasks -- have been made by, among others, Facebook Chief Executive Mark Zuckerberg in 2015, Tesla CEO Elon Musk in 2020 and OpenAI CEO Sam Altman in 2021.</p><p>OpenAI declined to comment or make Mr. Altman available. Tesla did not respond to a request for comment. Facebook's vice president of AI, Jerome Pesenti, says that his company believes the field of AI is better served by more scientific and realistic goals, rather than fuzzy concepts like creating human-level or even superhuman artificial intelligence. \"But,\" he adds, \"we are making great strides toward learning more like humans do.\"</p><p>The tendency for CEOs and researchers alike to say that their system \"understands\" a given input -- whether it's gigabytes of text, images or audio -- or that it can \"think\" about those inputs, or that it has any intention at all, are examples of what Drew McDermott, a computer scientist at Yale, once called \"wishful mnemonics.\" That he coined this phrase in 1976 makes it no less applicable to the present day.</p><p>\"I think AI is somewhat of a misnomer,\" says Daron Acemoglu, an economist at Massachusetts Institute of Technology whose research on AI's economic impacts requires a precise definition of the term. What we now call AI doesn't fulfill the early dreams of the field's founders -- either to create a system that can reason as a person does, or to create tools that can augment our abilities. \"Instead, it uses massive amounts of data to turn very, very narrow tasks into prediction problems,\" he says.</p><p>When AI researchers say that their algorithms are good at \"narrow\" tasks, what they mean is that, with enough data, it's possible to \"train\" their algorithms to, say, identify a cat. But unlike a human toddler, these algorithms tend not to be very adaptable. Identifying dogs means more or less starting from scratch.</p><p>Mr. Scott describes AI in similarly mundane terms. Whenever computers accomplish things that are hard for humans -- like being the best chess or Go player in the world -- it's easy to get the impression that we've \"solved\" intelligence, he says. But all we've demonstrated is that in general, things that are hard for humans are easy for computers, and vice versa.</p><p>AI algorithms, he points out, are just math. And one of math's functions is to simplify the world so our brains can tackle its otherwise dizzying complexity. The software we call AI, he continues, is just another way to arrive at complicated mathematical functions that help us do that.</p><p>Viral Shah is CEO of Julia Computing, a cloud-software company that makes tools for programmers who build AI and related systems. His customers range from universities working on better batteries for electric vehicles to pharmaceutical companies searching for new drugs.</p><p>Dr. Shah says he loves to debate how \"AI\" should be described and what that means for its future abilities, but he doesn't think it's worth getting hung up on semantics. \"This is the approach we're taking,\" he says. \"Let's not talk about the philosophical questions.\"</p><p>In its earliest days, in the mid-1950s, there was a friendly debate about what to call the field of AI. And while pioneering computer scientist John McCarthy proposed the winning name -- artificial intelligence -- another founder of the discipline suggested a more prosaic one.</p><p>\"Herbert Simon said we should call it 'complex information processing,'\" says Dr. Mitchell. \"What would the world be like if it was called that instead?\"</p>",
  "published": "2021-07-31T00:00:00.000Z",
  "tags": [
    {
      "id": "US4592001014",
      "nexusId": "10017781",
      "name": "International Business Machines Corporation",
      "offsets": [
        {
          "start": 523,
          "end": 526
        }
      ]
    }
  ]
}