{
  "_id": "cb8a546bc0fa80f9e81be6f905e95b3db4d82d2da42eee164b6c7884c643bb35",
  "feed": "wall-street-journal",
  "title": "Artificial Intelligence (A Special Report)  ---  The Best Team: AI and You:  Humans and machines can work well together. But the big question: Who does what?  ----  By Kartik Hosanagar",
  "text": "<p>   Research shows that humans and machines working together often perform better than either humans or artificial intelligence alone. Anecdote suggests the same: Chess grandmaster Garry Kasparov responded to his 1997 defeat by the IBM supercomputer Deep Blue by introducing a new form of chess in which humans could consult with computers before deciding on moves. The idea that human-machine teams could outperform in chess if they know how to work together then began to gain steam. </p><p>   But even if you're sold on the idea that the future of work is human-machine partnership, how exactly does one collaborate productively with AI? It isn't as if a human and AI can meet over lunch and hash it out. </p><p>   Still, as with cooperation among people, the most effective AI-human combinations often revolve around two key points. First, who decides who does what? And second, establishing -- and maintaining -- trust. </p><p>   Determining how responsibilities should be delegated -- or more specifically, who should do the delegating -- is a critical component of effective human-machine partnerships. Here, research offers some clues. In a recent study, researchers at the University of Cologne and the University of Minnesota asked people and machines -- in some cases working together and at other times working alone -- to match a set of images to one of 10 categories. In one of the groups, the machine could delegate to a human if it was having trouble making a decision. In another group, humans could delegate to the computer if they were having trouble completing the task. </p><p>   The results suggest humans aren't good at deciding who is best for the job: The teams in which the humans had the power to dole out work to AI made more categorization mistakes than the teams in which AI delegated tasks to humans, and more than AI working alone. (Humans working alone turned in the worst performance.) People, it seems, are poor judges of their own limitations. The humans in the study failed to ask AI for help when they needed it, and thus lost out on the chance to benefit from AI's recommendations. </p><p>   The results suggest that in many cases -- especially if a task is repetitive and one for which we have large training data sets -- it might be better for the AI system to be in control and delegate to humans when the system is in doubt. </p><p>   Delegation isn't the only hurdle when nurturing AI-people partnerships. There's also humans' aversion to algorithms. </p><p>   Over the years, researchers (myself included) have theorized that the reason people don't trust AI's advice is because they don't understand the decision-making process behind the algorithm. </p><p>   But in recent research, my collaborators and I found that people's trust in machines didn't improve all that much when the machine predictions came with detailed explanations. What helped more was when the study subjects could observe the AI's record over time. That is, the longer they worked with AI and could observe its performance, the more they trusted it. </p><p>   But even here, it is more complicated than just giving AI-human teams time to get to know each other. Research shows that people react more harshly to AI errors than human errors. </p><p>   One solution might be to present AI less as an infallible superintelligence and more as a co-worker of sorts, one that is superior in some areas, eager to improve in others and flawed in ways that humans aren't. </p><p>   Ultimately, we need to get better at understanding our strengths and limits relative to AI. It is perhaps not unlike how human chess players have gotten better by consulting AI. If this works for a chess grandmaster, it can work for organizations, too. </p><p>   --- </p><p>   Dr. Hosanagar (@khosanagar) is a professor studying technology and digital business at the Wharton School of the University of Pennsylvania and faculty co-lead of AI for Business. He also is the author of \"A Human's Guide to Machine Intelligence.\" Email him at reports@wsj.com. </p><p></p>",
  "published": "2022-04-11T06:01:00.000Z",
  "tags": [
    {
      "id": "US4592001014",
      "nexusId": "10017781",
      "name": "International Business Machines Corporation",
      "offsets": [
        {
          "start": 228,
          "end": 231
        }
      ]
    }
  ]
}